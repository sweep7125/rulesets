name: Generate sources (flattened xray + cidr)

on:
  schedule:
    - cron: "0 0 * * *"
  workflow_dispatch:

concurrency:
  group: sources-builder
  cancel-in-progress: true

permissions:
  contents: write

env:
  COMMIT_USER_NAME: ${{ github.actor }}
  COMMIT_USER_EMAIL: ${{ github.actor }}@users.noreply.github.com
  GOFLAGS: -buildvcs=false
  DEBIAN_FRONTEND: noninteractive
  TLD_RU_REGEX: '\.(ru|su|yandex|psk|xn--80adxhks|xn--80asehdb|xn--80aswg|xn--c1avg|xn--d1acj3b|xn--p1acf|xn--p1ai)$'

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v5
        with:
          fetch-depth: 1

      - name: Switch to branch sources (create if missing)
        run: |
          set -Eeuo pipefail
          if git ls-remote --exit-code --heads origin refs/heads/sources >/dev/null 2>&1; then
            git fetch --no-tags --depth=1 origin refs/heads/sources:refs/remotes/origin/sources
            git switch -c sources --track origin/sources || git switch sources
            git pull --ff-only || true
          else
            git switch -c sources
            git -c user.email="${COMMIT_USER_EMAIL}" -c user.name="${COMMIT_USER_NAME}" commit --allow-empty -m "Initialize sources"
            git push -u origin HEAD:sources
          fi

      - name: Prepare helpers and inputs from main
        run: |
          set -Eeuo pipefail
          mkdir -p .ci community _inputs
          git fetch --no-tags --depth=1 origin main
          git show origin/main:.ci/optimize.py > .ci/optimize.py
          git show origin/main:sections_in > sections_in || true
          git show origin/main:config_get.json > config_get.json 2>/dev/null || rm -f config_get.json
          cat > .ci/helpers.sh <<'SH'
          set -Eeuo pipefail
          OPT_PY="${GITHUB_WORKSPACE}/.ci/optimize.py"

          dom_xray_preserve() { python3 "$OPT_PY" domains "$1" "$2" --input-type xray  --target preserve; }
          dom_from_clean_to_xray_suffix() { python3 "$OPT_PY" domains "$1" "$2" --input-type clean --target suffix; }
          dom_from_clean_to_xray_exact()  { python3 "$OPT_PY" domains "$1" "$2" --input-type clean --target exact; }

          ip_opt() { python3 "$OPT_PY" ips "$1" "$2"; }
          get() { curl -fsSL --compressed --connect-timeout 10 --max-time 120 "$1" -o "$2"; }

          collect_geosite_stream_all() {
            for f in \
              geosite/refilter \
              geosite/refilter-community \
              geosite/antifilter-community \
              geosite/russia-inside \
              geosite/google-ai \
              geosite/youtube \
              geosite/discord
            do
              [[ -f "$f" || -f "$f.list" ]] || continue
              cat "$f" 2>/dev/null || true
              cat "$f.list" 2>/dev/null || true
              echo
            done
          }

          collect_refilter_only_stream() {
            for f in geosite/refilter; do
              [[ -f "$f" || -f "$f.list" ]] || continue
              cat "$f" 2>/dev/null || true
              cat "$f.list" 2>/dev/null || true
              echo
            done
          }
          SH

      - name: Checkout v2fly/domain-list-community (data only)
        uses: actions/checkout@v5
        with:
          repository: v2fly/domain-list-community
          path: community
          fetch-depth: 1
          sparse-checkout: |
            data
          sparse-checkout-cone-mode: true
          filter: blob:none

      - name: Clean output folders in workspace (root geosite/geoip)
        run: |
          set -Eeuo pipefail
          rm -rf geosite geoip
          mkdir -p geosite geoip

      - name: Build geosite/category-nongov-ru by stripping include before flatten
        run: |
          set -Eeuo pipefail
          source .ci/helpers.sh
          src_ru="community/data/category-ru"
          tmp="community/data/.tmp-category-nongov-ru"
          inc_re='^[[:space:]]*include:[[:space:]]*category-gov-ru([[:space:]]|$|#|@)'
          if [[ -f "$src_ru" ]]; then
            sed -E 's/\r$//' "$src_ru" | grep -vE "$inc_re" > "$tmp"
            dom_xray_preserve "$tmp" geosite/category-nongov-ru
            rm -f "$tmp" "$tmp.list"
          fi

      - name: Resolve keep-set from sections_in (recursive includes) and flatten → geosite/
        run: |
          set -Eeuo pipefail
          source .ci/helpers.sh
          DATA_DIR="community/data"
          INTEREST_FILE="sections_in"
          declare -A keep processed
          if [[ -f "$INTEREST_FILE" ]]; then
            while IFS= read -r line; do
              line="${line//$'\r'/}"; line="${line%%#*}"
              f="$(echo "$line" | xargs)"; [[ -n "$f" ]] && keep["$f"]=1
            done < "$INTEREST_FILE"
          fi
          for seed in category-ru category-gov-ru private; do keep["$seed"]=1; done
          changed=1
          while [[ $changed -eq 1 ]]; do
            changed=0
            for file in "${!keep[@]}"; do
              s="$(echo "$file | xargs")"; [[ -n "${processed[$s]:-}" ]] && continue
              processed["$s"]=1
              p="$DATA_DIR/$s"; [[ -f "$p" ]] || continue
              while IFS= read -r inc; do
                inc="${inc//$'\r'/}"; inc="${inc#include:}"; inc="${inc%%#*}"
                inc="$(echo "$inc" | xargs)"; [[ -z "$inc" ]] && continue
                [[ -z "${keep[$inc]:-}" ]] && { keep["$inc"]=1; changed=1; }
              done < <(grep '^include:' "$p" || true)
            done
          done
          for rel in "${!keep[@]}"; do
            src="$DATA_DIR/$rel"
            [[ -f "$src" ]] || continue
            out="geosite/$rel"
            mkdir -p "$(dirname "$out")"
            dom_xray_preserve "$src" "$out"
          done

      - name: Download external one-file DOMAIN sources (.src)
        run: |
          set -Eeuo pipefail
          source .ci/helpers.sh
          get "https://raw.githubusercontent.com/1andrevich/Re-filter-lists/main/community.lst" _inputs/refilter-community-domains.src
          get "https://community.antifilter.download/list/domains.lst" _inputs/antifilter-community-domains.src
          get "https://raw.githubusercontent.com/1andrevich/Re-filter-lists/main/domains_all.lst" _inputs/refilter-domains.src
          get "https://raw.githubusercontent.com/itdoginfo/allow-domains/main/Russia/inside-raw.lst" _inputs/russia-inside.src
          get "https://raw.githubusercontent.com/itdoginfo/allow-domains/main/Russia/outside-raw.lst" _inputs/russia-outside.src
          get "https://raw.githubusercontent.com/itdoginfo/allow-domains/main/Services/google_ai.lst" _inputs/google-ai.src
          get "https://raw.githubusercontent.com/sakib-m/Pi-hole-Torrent-Blocklist/main/all-torrent-trackers.txt" _inputs/torrent-trackers.src
          get "https://raw.githubusercontent.com/sakib-m/Pi-hole-Torrent-Blocklist/refs/heads/main/custom-tracker.txt" _inputs/torrent-trackers-custom.src

      - name: Normalize external DOMAIN sources → XRAY lists in geosite/
        run: |
          set -Eeuo pipefail
          source .ci/helpers.sh
          dom_from_clean_to_xray_suffix _inputs/refilter-community-domains.src geosite/refilter-community
          dom_from_clean_to_xray_suffix _inputs/antifilter-community-domains.src geosite/antifilter-community
          dom_from_clean_to_xray_suffix _inputs/refilter-domains.src            geosite/refilter
          dom_from_clean_to_xray_suffix _inputs/russia-inside.src               geosite/russia-inside
          dom_from_clean_to_xray_suffix _inputs/russia-outside.src              geosite/russia-outside
          dom_from_clean_to_xray_suffix _inputs/google-ai.src                   geosite/google-ai
          dom_from_clean_to_xray_exact  _inputs/torrent-trackers.src            geosite/torrent-trackers
          dom_from_clean_to_xray_exact  _inputs/torrent-trackers-custom.src     geosite/torrent-trackers-custom

      - name: Build derived geosite lists (category-ban-ru + refilter-no-ru)
        run: |
          set -Eeuo pipefail
          source .ci/helpers.sh
          tmp_all="$(mktemp)"
          collect_geosite_stream_all \
          | grep -E '^(domain:|[^:[:space:]])' \
          | sed -E '/^(full:|keyword:|regexp:)/d; s/^domain://' \
          | LC_ALL=C sort -u > "$tmp_all"
          { grep -E "${TLD_RU_REGEX}" "$tmp_all"; printf '%s\n' "jut.su" "habr.com" "4pda.to"; } \
          | LC_ALL=C sort -u > "geosite/category-ban-ru.list"
          tmp_refilter="$(mktemp)"
          collect_refilter_only_stream \
          | grep -E '^(domain:|[^:[:space:]])' \
          | sed -E '/^(full:|keyword:|regexp:)/d; s/^domain://' \
          | LC_ALL=C sort -u > "$tmp_refilter"
          grep -vE "${TLD_RU_REGEX}" "$tmp_refilter" | LC_ALL=C sort -u > "geosite/refilter-no-ru.list"
          dom_from_clean_to_xray_suffix geosite/refilter-no-ru.list geosite/refilter-no-ru
          rm -f "$tmp_all" "$tmp_refilter"

      - name: Build geosite/router (dedup + optimize, preserve)
        run: |
          set -Eeuo pipefail
          source .ci/helpers.sh
          tmp="$(mktemp)"
          {
            for f in \
              geosite/russia-inside \
              geosite/antifilter-community \
              geosite/google-ai
            do
              [[ -f "$f" || -f "$f.list" ]] || continue
              cat "$f" 2>/dev/null || true
              cat "$f.list" 2>/dev/null || true
              echo
            done
          } > "$tmp"
          dom_xray_preserve "$tmp" geosite/router
          rm -f "$tmp" "$tmp.list"

      - name: Build geosite/ru-bundle (dedup + optimize, preserve)
        run: |
          set -Eeuo pipefail
          source .ci/helpers.sh
          tmp="$(mktemp)"
          {
            for f in \
              geosite/russia-inside \
              geosite/antifilter-community \
              geosite/google-ai \
              geosite/refilter
            do
              [[ -f "$f" || -f "$f.list" ]] || continue
              cat "$f" 2>/dev/null || true
              cat "$f.list" 2>/dev/null || true
              echo
            done
          } > "$tmp"
          dom_xray_preserve "$tmp" geosite/ru-bundle
          rm -f "$tmp" "$tmp.list"

      - name: Download upstream geoip.dat & build base RU/PRIVATE (optional)
        run: |
          set -Eeuo pipefail
          if [[ -s config_get.json ]]; then
            git clone --depth=1 https://github.com/Loyalsoldier/geoip geoip-src
            pushd geoip-src >/dev/null
            go build ./
            popd >/dev/null
            ./geoip-src/geoip convert -c ./config_get.json
            python3 .ci/optimize.py ips extracted/ru.txt      geoip/ru
            python3 .ci/optimize.py ips extracted/private.txt geoip/private
            rm -rf extracted geoip-src
          fi

      - name: Download external one-file IP sources (.src)
        run: |
          set -Eeuo pipefail
          source .ci/helpers.sh
          get "https://raw.githubusercontent.com/GhostRooter0953/discord-voice-ips/master/voice_domains/discord-voice-ip-list" _inputs/discord-voice-ips.src
          get "https://core.telegram.org/resources/cidr.txt" _inputs/telegram-ips.src
          get "https://www.cloudflare.com/ips-v4" _inputs/cloudflare4.src
          get "https://www.cloudflare.com/ips-v6" _inputs/cloudflare6.src
          get "https://raw.githubusercontent.com/1andrevich/Re-filter-lists/main/ipsum.lst" _inputs/refilter-ips.src
          get "https://raw.githubusercontent.com/1andrevich/Re-filter-lists/main/community_ips.lst" _inputs/refilter-community-ips.src
          { cat _inputs/cloudflare4.src; echo; cat _inputs/cloudflare6.src; } > _inputs/cloudflare-all.src
          { cat _inputs/refilter-ips.src; echo; cat _inputs/discord-voice-ips.src; } > _inputs/ru-bundle.src

      - name: Normalize IP sources → CIDR lists in geoip/
        run: |
          set -Eeuo pipefail
          source .ci/helpers.sh
          ip_opt _inputs/discord-voice-ips.src      geoip/discord-voice
          ip_opt _inputs/telegram-ips.src           geoip/telegram
          ip_opt _inputs/cloudflare4.src            geoip/cloudflare4
          ip_opt _inputs/cloudflare6.src            geoip/cloudflare6
          ip_opt _inputs/cloudflare-all.src         geoip/cloudflare
          ip_opt _inputs/refilter-ips.src           geoip/refilter
          ip_opt _inputs/refilter-community-ips.src geoip/refilter-community
          ip_opt _inputs/ru-bundle.src geoip/ru-bundle

      - name: Build derived geoip lists (category-ban-ru + refilter-no-russia + ru-no-refilter)
        run: |
          set -Eeuo pipefail
          python3 - <<'PY'
          import os, ipaddress
          from ipaddress import collapse_addresses, summarize_address_range

          def read_nets(p):
              if not os.path.exists(p): return []
              out=[]
              with open(p,'r',encoding='utf-8',errors='ignore') as f:
                  for t in f:
                      t=t.strip()
                      if not t or t.startswith('#'): continue
                      try: out.append(ipaddress.ip_network(t, strict=False))
                      except: pass
              return out

          def read_any(base):
              return read_nets(base + ".list") or read_nets(base)

          def normalize(nets):
              v4=[n for n in nets if n.version==4]
              v6=[n for n in nets if n.version==6]
              return list(collapse_addresses(v4)) + list(collapse_addresses(v6))

          def split_sorted_by_family(nets):
              A4 = sorted([n for n in nets if n.version==4], key=lambda n:int(n.network_address))
              A6 = sorted([n for n in nets if n.version==6], key=lambda n:int(n.network_address))
              return A4, A6

          def inter_linear(A, B):
              out=[]; i=j=0
              while i<len(A) and j<len(B):
                  a,b=A[i],B[j]
                  if int(a.broadcast_address)<int(b.network_address): i+=1; continue
                  if int(b.broadcast_address)<int(a.network_address): j+=1; continue
                  lo=max(int(a.network_address),int(b.network_address))
                  hi=min(int(a.broadcast_address),int(b.broadcast_address))
                  lo_addr = type(a.network_address)(lo)
                  hi_addr = type(a.network_address)(hi)
                  out.extend(summarize_address_range(lo_addr, hi_addr))
                  if int(a.broadcast_address)<int(b.broadcast_address): i+=1
                  else: j+=1
              return out

          def diff_linear(A, B):
              out=[]; i=j=0
              while i < len(A):
                  a=A[i]
                  a_lo=int(a.network_address); a_hi=int(a.broadcast_address)
                  cur=a_lo
                  while j < len(B) and int(B[j].broadcast_address) < cur:
                      j+=1
                  k=j
                  while k < len(B) and int(B[k].network_address) <= a_hi:
                      b=B[k]
                      b_lo=int(b.network_address); b_hi=int(b.broadcast_address)
                      if b_lo > cur:
                          lo_addr = type(a.network_address)(cur)
                          hi_addr = type(a.network_address)(min(a_hi, b_lo-1))
                          out.extend(summarize_address_range(lo_addr, hi_addr))
                      if b_hi + 1 > a_hi:
                          cur=a_hi+1
                          break
                      else:
                          cur=b_hi+1
                      k+=1
                  if cur <= a_hi:
                      lo_addr = type(a.network_address)(cur)
                      hi_addr = type(a.network_address)(a_hi)
                      out.extend(summarize_address_range(lo_addr, hi_addr))
                  if k>j: j=k
                  i+=1
              return out

          def op_intersection(A, B):
              A4,A6 = split_sorted_by_family(normalize(A))
              B4,B6 = split_sorted_by_family(normalize(B))
              return normalize(inter_linear(A4,B4) + inter_linear(A6,B6))

          def op_difference(A, B):
              A4,A6 = split_sorted_by_family(normalize(A))
              B4,B6 = split_sorted_by_family(normalize(B))
              return normalize(diff_linear(A4,B4) + diff_linear(A6,B6))

          def write_list(path, nets):
              os.makedirs(os.path.dirname(path), exist_ok=True)
              nets_sorted = sorted(nets, key=lambda n:(n.version, n.prefixlen, int(n.network_address)))
              with open(path,"w",encoding="utf-8") as f:
                  for n in nets_sorted:
                      f.write(f"{n.network_address}/{n.prefixlen}\n")

          ru     = read_any("geoip/ru")
          rf_ref = read_any("geoip/refilter")
          rf_com = read_any("geoip/refilter-community")
          rf_all = rf_ref + rf_com

          if ru:
              cat = op_intersection(rf_all, ru)
              dff = op_difference(rf_ref, ru)
              rnf = op_difference(ru, rf_ref)
          else:
              cat = []
              dff = normalize(rf_ref)
              rnf = []

          write_list("geoip/category-ban-ru.list",   cat)
          write_list("geoip/refilter-no-russia.list", dff)
          write_list("geoip/ru-no-refilter.list",     rnf)
          PY

      - name: Build geoip/router (dedup + optimize)
        run: |
          set -Eeuo pipefail
          source .ci/helpers.sh
          tmp="$(mktemp)"
          {
            for f in \
              geoip/discord-voice
            do
              [[ -f "$f" || -f "$f.list" ]] || continue
              cat "$f" 2>/dev/null || true
              cat "$f.list" 2>/dev/null || true
              echo
            done
          } > "$tmp"
          ip_opt "$tmp" geoip/router
          rm -f "$tmp" "$tmp.list"

      - name: Commit ONLY geosite/ and geoip/ to sources branch
        run: |
          set -Eeuo pipefail
          git config --local user.email "${COMMIT_USER_EMAIL}"
          git config --local user.name  "${COMMIT_USER_NAME}"
          git ls-files -z | xargs -0 -r git rm -f --cached
          git add -f geosite geoip
          git diff --staged --quiet && exit 0
          git commit -m "Update sources (geosite + geoip only) $(date -u +'%Y-%m-%dT%H:%M:%SZ')"
          git push || true
