name: Generate sources (flattened xray + cidr)

on:
  schedule:
    - cron: "0 0 * * *"
  workflow_dispatch:

concurrency:
  group: sources-builder
  cancel-in-progress: true

permissions:
  contents: write

env:
  COMMIT_USER_NAME: ${{ github.actor }}
  COMMIT_USER_EMAIL: ${{ github.actor }}@users.noreply.github.com
  GOFLAGS: -buildvcs=false
  DEBIAN_FRONTEND: noninteractive

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v5
        with:
          fetch-depth: 1

      - name: Switch to branch sources (create if missing)
        run: |
          set -Eeuo pipefail
          if git ls-remote --exit-code --heads origin refs/heads/sources >/dev/null 2>&1; then
            git fetch --no-tags --depth=1 origin refs/heads/sources:refs/remotes/origin/sources
            git switch -c sources --track origin/sources || git switch sources
            git pull --ff-only
          else
            git switch -c sources
            git -c user.email="${{ env.COMMIT_USER_EMAIL }}" -c user.name="${{ env.COMMIT_USER_NAME }}" commit --allow-empty -m "Initialize sources"
            git push -u origin HEAD:sources
          fi

      - name: Prepare helpers and inputs from main
        run: |
          set -Eeuo pipefail
          mkdir -p .ci sources/geosite sources/geoip _inputs
          git fetch --no-tags --depth=1 origin main
          git show origin/main:.ci/optimize.py > .ci/optimize.py
          git show origin/main:sections_in > sections_in || true
          git show origin/main:config_get.json > config_get.json || true
          cat > .ci/helpers.sh <<'SH'
          set -Eeuo pipefail
          OPT_PY="${GITHUB_WORKSPACE}/.ci/optimize.py"
          dom_xray_preserve()             { python3 "$OPT_PY" domains "$1" "$2" --input-type xray  --target preserve --view xray; }
          dom_from_clean_to_xray_suffix() { python3 "$OPT_PY" domains "$1" "$2" --input-type clean --target suffix   --view xray; }
          dom_from_clean_to_xray_exact()  { python3 "$OPT_PY" domains "$1" "$2" --input-type clean --target exact    --view xray; }
          ip_opt()                        { python3 "$OPT_PY" ips "$1" "$2"; }
          get() { curl -fsSL --compressed --connect-timeout 10 --max-time 120 "$1" -o "$2"; }
          SH

      - name: Checkout v2fly/domain-list-community (data only)
        uses: actions/checkout@v5
        with:
          repository: v2fly/domain-list-community
          path: community
          fetch-depth: 1
          sparse-checkout: |
            data
          sparse-checkout-cone-mode: true
          filter: blob:none

      - name: Recreate sources folders
        run: |
          set -Eeuo pipefail
          rm -rf sources/geosite sources/geoip
          mkdir -p sources/geosite sources/geoip

      - name: Build geosite/category-nongov-ru by stripping include before flatten
        run: |
          set -Eeuo pipefail
          src_ru="community/data/category-ru"
          inc_re='^[[:space:]]*include:[[:space:]]*category-gov-ru([[:space:]]|$|#|@)'
          if [[ -f "${src_ru}" ]]; then
            tmp="$(mktemp)"
            sed -E 's/\r$//' "${src_ru}" | grep -vE "${inc_re}" > "${tmp}"
            python3 .ci/optimize.py domains "${tmp}" sources/geosite/category-nongov-ru \
              --input-type xray --target preserve --view xray
            rm -f "${tmp}"
          else
            echo "WARN: community/data/category-ru not found; skip category-nongov-ru" >&2
          fi


      - name: Flatten sections_in → sources/geosite (XRAY, no include)
        if: success()
        run: |
          set -Eeuo pipefail
          source .ci/helpers.sh
          if [[ -f sections_in ]]; then
            while IFS= read -r s; do
              s="${s%%#*}"; s="$(echo "$s" | xargs)"
              [[ -z "$s" ]] && continue
              src="community/data/$s"
              [[ -f "$src" ]] || { echo "skip missing: $s"; continue; }
              dom_xray_preserve "$src" "sources/geosite/$s"
            done < sections_in
          fi

      - name: Download external one-file DOMAIN sources (.src)
        run: |
          set -Eeuo pipefail
          source .ci/helpers.sh
          urls=( \
            "https://raw.githubusercontent.com/1andrevich/Re-filter-lists/main/community.lst _inputs/refilter-community-domains.src" \
            "https://community.antifilter.download/list/domains.lst _inputs/antifilter-community-domains.src" \
            "https://raw.githubusercontent.com/1andrevich/Re-filter-lists/main/domains_all.lst _inputs/refilter-domains.src" \
            "https://raw.githubusercontent.com/itdoginfo/allow-domains/main/Russia/inside-raw.lst _inputs/russia-inside.src" \
            "https://raw.githubusercontent.com/itdoginfo/allow-domains/main/Russia/outside-raw.lst _inputs/russia-outside.src" \
            "https://raw.githubusercontent.com/itdoginfo/allow-domains/main/Services/google_ai.lst _inputs/google-ai.src" \
            "https://raw.githubusercontent.com/sakib-m/Pi-hole-Torrent-Blocklist/main/all-torrent-trackers.txt _inputs/torrent-trackers.src" \
            "https://raw.githubusercontent.com/sakib-m/Pi-hole-Torrent-Blocklist/refs/heads/main/custom-tracker.txt _inputs/torrent-trackers-custom.src" \
          )
          pids=(); MAXJ=6
          for pair in "${urls[@]}"; do
            read -r u o <<<"$pair"
            get "$u" "$o" & pids+=($!)
            if (( ${#pids[@]} >= MAXJ )); then wait "${pids[0]}"; pids=("${pids[@]:1}"); fi
          done
          for pid in "${pids[@]}"; do wait "$pid"; done

      - name: Normalize DOMAIN sources → XRAY lists in sources/geosite
        run: |
          set -Eeuo pipefail
          source .ci/helpers.sh
          convs=( \
            "suffix _inputs/refilter-community-domains.src sources/geosite/refilter-community-domains" \
            "suffix _inputs/antifilter-community-domains.src sources/geosite/antifilter-community-domains" \
            "suffix _inputs/refilter-domains.src sources/geosite/refilter-domains" \
            "suffix _inputs/russia-inside.src sources/geosite/russia-inside" \
            "suffix _inputs/russia-outside.src sources/geosite/russia-outside" \
            "suffix _inputs/google-ai.src sources/geosite/google-ai" \
            "exact  _inputs/torrent-trackers.src sources/geosite/torrent-trackers" \
            "exact  _inputs/torrent-trackers-custom.src sources/geosite/torrent-trackers-custom" \
          )
          for line in "${convs[@]}"; do
            read -r t i o <<<"$line"
            if [[ "$t" == "suffix" ]]; then
              dom_from_clean_to_xray_suffix "$i" "$o"
            else
              dom_from_clean_to_xray_exact "$i" "$o"
            fi
          done

      - name: Build derived geosite/category-ban-ru (XRAY)
        run: |
          set -Eeuo pipefail
          t_regex='\.(ru|su|yandex|psk|xn--80adxhks|xn--80asehdb|xn--80aswg|xn--c1avg|xn--d1acj3b|xn--p1acf|xn--p1ai)$'
          tmp="$(mktemp)"
          {
            for f in \
              "sources/geosite/refilter-domains" \
              "sources/geosite/youtube" \
              "sources/geosite/discord" \
              "sources/geosite/antifilter-community-domains" \
              "sources/geosite/russia-inside" \
              "sources/geosite/google-ai" \
              "sources/geosite/refilter-community-domains"
            do
              [[ -f "$f" || -f "$f.list" ]] || continue
              cat "$f" 2>/dev/null || true
              cat "$f.list" 2>/dev/null || true
              echo
            done
          } | grep -E '^(domain:|[^:[:space:]])' \
            | sed -E '/^(full:|keyword:|regexp:)/d; s/^domain://' \
            | grep -E "$t_regex" | sort -u > "$tmp"
          printf '%s\n' "jut.su" "habr.com" "4pda.to" | cat - "$tmp" | sort -u > "sources/geosite/category-ban-ru.list"
          rm -f "$tmp"

      - name: Download upstream geoip.dat & build base RU/PRIVATE
        run: |
          set -Eeuo pipefail
          if [[ ! -s config_get.json ]]; then
            echo "config_get.json not found in main; skipping upstream extraction" >&2
          else
            uri="$(python3 - <<'PY'
          import json,sys
          with open("config_get.json","r",encoding="utf-8") as f: cfg=json.load(f)
          for it in cfg.get("input",[]):
              if it.get("type")=="v2rayGeoIPDat":
                  print(it["args"]["uri"]); sys.exit(0)
          sys.exit(1)
          PY
          )"
            curl -fsSL --compressed -o _inputs/upstream-geoip.dat "$uri"
            git clone --depth=1 https://github.com/Loyalsoldier/geoip geoip-src
            pushd geoip-src >/dev/null
            go build ./ 
            popd >/dev/null
            ./geoip-src/geoip convert -c ./config_get.json
            python3 .ci/optimize.py ips extracted/ru.txt sources/geoip/ru
            python3 .ci/optimize.py ips extracted/private.txt sources/geoip/private
            rm -rf extracted geoip-src _inputs/upstream-geoip.dat
          fi

      - name: Download external one-file IP sources (.src)
        run: |
          set -Eeuo pipefail
          source .ci/helpers.sh
          urls=( \
            "https://raw.githubusercontent.com/GhostRooter0953/discord-voice-ips/master/voice_domains/discord-voice-ip-list _inputs/discord-voice-ips.src" \
            "https://core.telegram.org/resources/cidr.txt _inputs/telegram-ips.src" \
            "https://www.cloudflare.com/ips-v4 _inputs/cloudflare4.src" \
            "https://www.cloudflare.com/ips-v6 _inputs/cloudflare6.src" \
            "https://raw.githubusercontent.com/1andrevich/Re-filter-lists/main/ipsum.lst _inputs/refilter-ips.src" \
            "https://raw.githubusercontent.com/1andrevich/Re-filter-lists/main/community_ips.lst _inputs/refilter-community-ips.src" \
          )
          pids=(); MAXJ=6
          for pair in "${urls[@]}"; do
            read -r u o <<<"$pair"
            get "$u" "$o" & pids+=($!)
            if (( ${#pids[@]} >= MAXJ )); then wait "${pids[0]}"; pids=("${pids[@]:1}"); fi
          done
          for pid in "${pids[@]}"; do wait "$pid"; done
          { cat _inputs/cloudflare4.src; echo; cat _inputs/cloudflare6.src; } > _inputs/cloudflare-all.src

      - name: Normalize IP sources → CIDR lists in sources/geoip
        run: |
          set -Eeuo pipefail
          source .ci/helpers.sh
          ip_opt _inputs/discord-voice-ips.src        sources/geoip/discord-voice-ips
          ip_opt _inputs/telegram-ips.src             sources/geoip/telegram
          ip_opt _inputs/cloudflare4.src              sources/geoip/cloudflare-ipv4
          ip_opt _inputs/cloudflare6.src              sources/geoip/cloudflare-ipv6
          ip_opt _inputs/cloudflare-all.src           sources/geoip/cloudflare-all
          ip_opt _inputs/refilter-ips.src             sources/geoip/refilter-ips
          ip_opt _inputs/refilter-community-ips.src   sources/geoip/refilter-community-ips

      - name: Build derived geoip/category-ban-ru (intersection RU ∩ refilter)
        run: |
          set -Eeuo pipefail
          python3 - <<'PY'
          import os, ipaddress
          def read_nets(p):
              if not os.path.exists(p): return []
              out=[]
              with open(p,'r',encoding='utf-8',errors='ignore') as f:
                  for t in f:
                      t=t.strip()
                      if not t or t.startswith('#'): continue
                      try: out.append(ipaddress.ip_network(t,strict=False))
                      except: pass
              return out
          def collapse(nets):
              v4=sorted([n for n in nets if n.version==4], key=lambda n:(int(n.network_address), int(n.broadcast_address)))
              v6=sorted([n for n in nets if n.version==6], key=lambda n:(int(n.network_address), int(n.broadcast_address)))
              from ipaddress import collapse_addresses
              return list(collapse_addresses(v4))+list(collapse_addresses(v6))
          def intersect(A,B):
              A=collapse(A); B=collapse(B)
              def inter(X,Y):
                  i=j=0; out=[]
                  from ipaddress import summarize_address_range, ip_address
                  while i<len(X) and j<len(Y):
                      a=X[i]; b=Y[j]
                      if int(a.broadcast_address)<int(b.network_address): i+=1; continue
                      if int(b.broadcast_address)<int(a.network_address): j+=1; continue
                      lo=max(int(a.network_address), int(b.network_address))
                      hi=min(int(a.broadcast_address), int(b.broadcast_address))
                      out.extend(summarize_address_range(ip_address(lo), ip_address(hi)))
                      if int(a.broadcast_address) < int(b.broadcast_address): i+=1
                      else: j+=1
                  return out
              A4=[n for n in A if n.version==4]; B4=[n for n in B if n.version==4]
              A6=[n for n in A if n.version==6]; B6=[n for n in B if n.version==6]
              return collapse(inter(A4,B4)+inter(A6,B6))
          ru  = read_nets("sources/geoip/ru.list")  or read_nets("sources/geoip/ru")
          rf  = (read_nets("sources/geoip/refilter-ips.list")+
                 read_nets("sources/geoip/refilter-community-ips.list"))
          out = intersect(ru, rf)
          os.makedirs("sources/geoip", exist_ok=True)
          with open("sources/geoip/category-ban-ru.list","w",encoding="utf-8") as f:
              for n in sorted(out,key=lambda n:(n.version,n.prefixlen,int(n.network_address))):
                  f.write(f"{n.network_address}/{n.prefixlen}\n")
          PY

      - name: Stamp date
        run: echo "DATE=$(date -u +'%Y-%m-%dT%H:%M:%SZ')" >> "$GITHUB_ENV"

      - name: Commit sources/
        run: |
          set -Eeuo pipefail
          git config --local user.email "${COMMIT_USER_EMAIL}"
          git config --local user.name  "${COMMIT_USER_NAME}"
          git add -A sources sections_in config_get.json .ci/optimize.py || true
          if git diff --staged --quiet; then
            echo "No changes to commit"
            exit 0
          fi
          git commit -m "Update sources ${DATE}"
          git push || true
